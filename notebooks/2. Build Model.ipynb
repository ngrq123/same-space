{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c4618b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "from torchvision.transforms import Resize\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd2ce98e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV3(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): Conv2dNormActivation(\n",
      "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
      "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv2dNormActivation(\n",
      "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
      "      (2): Hardswish()\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
      "    (1): Hardswish()\n",
      "    (2): Dropout(p=0.2, inplace=True)\n",
      "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "weights = MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
    "model = mobilenet_v3_large(weights=weights)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0224a015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c5ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.dataset_duplicate_image import DuplicateImageDataset\n",
    "from scripts.model import SiameseDuplicateImageNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567bddd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8500675",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseDuplicateImageNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1dee4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DuplicateImageDataset('../data/Training Data', transforms=[Resize((224, 224), antialias=True)])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d250a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[248, 248, 248,  ..., 233, 235, 235],\n",
       "           [248, 248, 248,  ..., 233, 235, 235],\n",
       "           [249, 249, 249,  ..., 233, 235, 234],\n",
       "           ...,\n",
       "           [159, 160, 149,  ..., 232, 238, 236],\n",
       "           [180, 180, 178,  ..., 221, 233, 238],\n",
       "           [186, 182, 177,  ..., 220, 222, 231]],\n",
       " \n",
       "          [[225, 225, 225,  ..., 227, 226, 226],\n",
       "           [225, 225, 225,  ..., 227, 226, 226],\n",
       "           [226, 226, 226,  ..., 227, 226, 225],\n",
       "           ...,\n",
       "           [109, 109, 102,  ..., 224, 230, 226],\n",
       "           [129, 125, 121,  ..., 208, 224, 230],\n",
       "           [132, 130, 122,  ..., 208, 213, 226]],\n",
       " \n",
       "          [[194, 194, 194,  ..., 221, 221, 221],\n",
       "           [194, 194, 194,  ..., 221, 221, 221],\n",
       "           [195, 195, 195,  ..., 221, 221, 220],\n",
       "           ...,\n",
       "           [ 64,  64,  58,  ..., 216, 226, 220],\n",
       "           [ 79,  72,  65,  ..., 199, 220, 227],\n",
       "           [ 84,  82,  72,  ..., 195, 204, 220]]],\n",
       " \n",
       " \n",
       "         [[[178, 175, 173,  ..., 163, 164, 163],\n",
       "           [178, 178, 179,  ..., 192, 193, 193],\n",
       "           [171, 172, 172,  ..., 191, 190, 184],\n",
       "           ...,\n",
       "           [129, 116, 128,  ..., 153, 156, 160],\n",
       "           [117, 130, 107,  ..., 145, 156, 163],\n",
       "           [126, 137, 116,  ..., 118, 131, 140]],\n",
       " \n",
       "          [[124, 122, 117,  ..., 108, 107, 106],\n",
       "           [126, 125, 120,  ..., 139, 139, 138],\n",
       "           [117, 121, 120,  ..., 140, 138, 132],\n",
       "           ...,\n",
       "           [114, 102, 113,  ...,  69,  73,  74],\n",
       "           [105, 118,  93,  ...,  65,  73,  77],\n",
       "           [115, 126, 103,  ...,  40,  49,  54]],\n",
       " \n",
       "          [[ 48,  45,  42,  ...,  17,  17,  16],\n",
       "           [ 54,  48,  48,  ...,  41,  40,  40],\n",
       "           [ 36,  40,  46,  ...,  41,  37,  31],\n",
       "           ...,\n",
       "           [ 96,  83,  97,  ...,  77,  80,  81],\n",
       "           [ 90, 104,  79,  ...,  71,  80,  85],\n",
       "           [105, 116,  91,  ...,  46,  55,  62]]],\n",
       " \n",
       " \n",
       "         [[[219, 218, 216,  ..., 210, 214, 216],\n",
       "           [219, 218, 215,  ..., 214, 217, 213],\n",
       "           [216, 216, 215,  ..., 214, 215, 213],\n",
       "           ...,\n",
       "           [171, 126, 124,  ..., 165, 163, 166],\n",
       "           [172, 126, 124,  ..., 172, 166, 167],\n",
       "           [173, 125, 123,  ..., 175, 168, 170]],\n",
       " \n",
       "          [[206, 200, 199,  ..., 197, 204, 206],\n",
       "           [206, 200, 198,  ..., 203, 207, 203],\n",
       "           [202, 197, 198,  ..., 203, 205, 203],\n",
       "           ...,\n",
       "           [110,  30,  28,  ...,  89,  91,  98],\n",
       "           [111,  30,  28,  ...,  97,  94,  99],\n",
       "           [112,  29,  27,  ..., 100,  97, 101]],\n",
       " \n",
       "          [[195, 188, 189,  ..., 195, 203, 205],\n",
       "           [195, 188, 189,  ..., 201, 206, 202],\n",
       "           [191, 186, 189,  ..., 202, 204, 202],\n",
       "           ...,\n",
       "           [ 84,   4,   2,  ...,  66,  69,  78],\n",
       "           [ 86,   5,   1,  ...,  73,  72,  79],\n",
       "           [ 87,   4,   1,  ...,  76,  75,  82]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[192, 188, 185,  ..., 151, 151, 150],\n",
       "           [196, 193, 189,  ..., 152, 151, 150],\n",
       "           [203, 199, 194,  ..., 153, 151, 150],\n",
       "           ...,\n",
       "           [ 49,  48,  49,  ...,  77,  71,  70],\n",
       "           [ 51,  47,  46,  ...,  78,  74,  73],\n",
       "           [ 52,  45,  43,  ...,  79,  76,  76]],\n",
       " \n",
       "          [[133, 133, 130,  ..., 140, 141, 140],\n",
       "           [136, 135, 132,  ..., 141, 140, 139],\n",
       "           [142, 140, 137,  ..., 142, 140, 139],\n",
       "           ...,\n",
       "           [ 34,  31,  28,  ...,  64,  58,  55],\n",
       "           [ 30,  28,  27,  ...,  65,  61,  59],\n",
       "           [ 27,  24,  24,  ...,  66,  63,  61]],\n",
       " \n",
       "          [[ 41,  38,  36,  ..., 121, 117, 117],\n",
       "           [ 41,  41,  40,  ..., 121, 118, 118],\n",
       "           [ 36,  38,  39,  ..., 120, 120, 122],\n",
       "           ...,\n",
       "           [  9,   6,   5,  ...,  47,  41,  39],\n",
       "           [  6,   4,   3,  ...,  48,  44,  41],\n",
       "           [  5,   1,   0,  ...,  49,  46,  42]]],\n",
       " \n",
       " \n",
       "         [[[175, 176, 177,  ...,  35,  34,  33],\n",
       "           [175, 176, 177,  ...,  34,  33,  33],\n",
       "           [176, 176, 177,  ...,  34,  32,  33],\n",
       "           ...,\n",
       "           [ 47,  42,  34,  ...,  23,  23,  23],\n",
       "           [ 41,  36,  29,  ...,  23,  23,  24],\n",
       "           [ 36,  30,  32,  ...,  23,  23,  24]],\n",
       " \n",
       "          [[178, 179, 180,  ...,  39,  38,  37],\n",
       "           [178, 179, 180,  ...,  38,  37,  37],\n",
       "           [179, 179, 180,  ...,  38,  36,  37],\n",
       "           ...,\n",
       "           [ 48,  42,  35,  ...,  22,  22,  22],\n",
       "           [ 42,  37,  30,  ...,  22,  22,  23],\n",
       "           [ 37,  31,  33,  ...,  22,  22,  23]],\n",
       " \n",
       "          [[183, 184, 185,  ...,  40,  39,  38],\n",
       "           [183, 184, 185,  ...,  39,  38,  38],\n",
       "           [184, 184, 185,  ...,  39,  37,  38],\n",
       "           ...,\n",
       "           [ 56,  50,  41,  ...,  18,  18,  18],\n",
       "           [ 47,  43,  35,  ...,  18,  18,  19],\n",
       "           [ 41,  35,  37,  ...,  18,  18,  19]]],\n",
       " \n",
       " \n",
       "         [[[116, 119, 121,  ..., 147, 135,  97],\n",
       "           [118, 121, 124,  ..., 150, 136,  75],\n",
       "           [120, 122, 125,  ..., 150, 125,  57],\n",
       "           ...,\n",
       "           [ 18,  18,  18,  ...,  10,  10,  10],\n",
       "           [ 18,  18,  18,  ...,  10,  10,  10],\n",
       "           [ 18,  18,  18,  ...,  10,  10,  10]],\n",
       " \n",
       "          [[111, 114, 116,  ..., 114, 104,  68],\n",
       "           [113, 116, 119,  ..., 116, 103,  50],\n",
       "           [115, 117, 120,  ..., 117,  95,  36],\n",
       "           ...,\n",
       "           [  8,   8,   8,  ...,   4,   4,   4],\n",
       "           [  8,   8,   8,  ...,   4,   4,   4],\n",
       "           [  8,   8,   8,  ...,   4,   4,   4]],\n",
       " \n",
       "          [[108, 111, 111,  ...,  68,  57,  38],\n",
       "           [110, 113, 114,  ...,  67,  57,  28],\n",
       "           [112, 114, 116,  ...,  65,  55,  21],\n",
       "           ...,\n",
       "           [  7,   7,   5,  ...,   6,   6,   6],\n",
       "           [  7,   7,   5,  ...,   6,   6,   6],\n",
       "           [  7,   7,   5,  ...,   6,   6,   6]]]], dtype=torch.uint8),\n",
       " tensor([[[[194, 194, 195,  ..., 186, 186, 186],\n",
       "           [194, 194, 195,  ..., 186, 186, 186],\n",
       "           [194, 195, 195,  ..., 185, 185, 185],\n",
       "           ...,\n",
       "           [122, 125, 123,  ..., 154, 154, 146],\n",
       "           [126, 126, 132,  ..., 152, 156, 155],\n",
       "           [127, 131, 140,  ..., 157, 149, 150]],\n",
       " \n",
       "          [[155, 155, 156,  ..., 153, 153, 153],\n",
       "           [155, 155, 156,  ..., 153, 153, 153],\n",
       "           [155, 156, 156,  ..., 152, 152, 152],\n",
       "           ...,\n",
       "           [ 78,  82,  80,  ..., 131, 131, 122],\n",
       "           [ 80,  80,  84,  ..., 130, 134, 131],\n",
       "           [ 80,  84,  92,  ..., 134, 126, 127]],\n",
       " \n",
       "          [[114, 114, 115,  ..., 112, 112, 112],\n",
       "           [114, 114, 115,  ..., 112, 112, 112],\n",
       "           [114, 115, 115,  ..., 111, 111, 111],\n",
       "           ...,\n",
       "           [ 36,  39,  38,  ...,  97,  94,  95],\n",
       "           [ 38,  38,  41,  ...,  89, 100, 102],\n",
       "           [ 38,  42,  48,  ...,  98,  97,  91]]],\n",
       " \n",
       " \n",
       "         [[[159, 161, 162,  ..., 194, 194, 193],\n",
       "           [157, 159, 162,  ..., 194, 193, 193],\n",
       "           [158, 159, 160,  ..., 194, 193, 192],\n",
       "           ...,\n",
       "           [180, 178, 182,  ..., 217, 216, 214],\n",
       "           [177, 177, 183,  ..., 215, 216, 216],\n",
       "           [173, 172, 178,  ..., 212, 212, 213]],\n",
       " \n",
       "          [[158, 160, 161,  ..., 180, 180, 179],\n",
       "           [156, 158, 161,  ..., 180, 179, 179],\n",
       "           [157, 158, 159,  ..., 180, 179, 178],\n",
       "           ...,\n",
       "           [167, 165, 167,  ..., 184, 184, 182],\n",
       "           [164, 164, 168,  ..., 183, 183, 183],\n",
       "           [160, 159, 164,  ..., 180, 180, 181]],\n",
       " \n",
       "          [[164, 166, 167,  ..., 167, 167, 166],\n",
       "           [162, 164, 167,  ..., 167, 166, 166],\n",
       "           [163, 164, 165,  ..., 167, 166, 165],\n",
       "           ...,\n",
       "           [151, 149, 151,  ..., 147, 146, 144],\n",
       "           [145, 146, 152,  ..., 145, 147, 147],\n",
       "           [139, 138, 146,  ..., 140, 139, 140]]],\n",
       " \n",
       " \n",
       "         [[[182, 193, 188,  ..., 152, 151, 149],\n",
       "           [182, 191, 186,  ..., 151, 151, 149],\n",
       "           [181, 188, 184,  ..., 148, 149, 148],\n",
       "           ...,\n",
       "           [167, 165, 165,  ...,  80,  78,  78],\n",
       "           [169, 164, 165,  ...,  80,  78,  78],\n",
       "           [171, 165, 166,  ...,  80,  78,  78]],\n",
       " \n",
       "          [[187, 189, 181,  ..., 127, 127, 125],\n",
       "           [187, 190, 182,  ..., 127, 127, 125],\n",
       "           [186, 190, 182,  ..., 126, 125, 124],\n",
       "           ...,\n",
       "           [156, 150, 150,  ...,  63,  62,  63],\n",
       "           [154, 151, 152,  ...,  64,  62,  63],\n",
       "           [155, 152, 155,  ...,  64,  62,  63]],\n",
       " \n",
       "          [[199, 191, 171,  ..., 101, 101,  99],\n",
       "           [197, 192, 171,  ..., 101, 101,  99],\n",
       "           [193, 193, 171,  ...,  99,  99,  98],\n",
       "           ...,\n",
       "           [128, 123, 123,  ...,  45,  46,  44],\n",
       "           [128, 124, 125,  ...,  46,  46,  44],\n",
       "           [129, 125, 127,  ...,  46,  46,  44]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[226, 226, 226,  ..., 215, 215, 215],\n",
       "           [226, 226, 226,  ..., 215, 215, 215],\n",
       "           [229, 229, 229,  ..., 215, 215, 215],\n",
       "           ...,\n",
       "           [121, 136, 155,  ..., 190, 186, 185],\n",
       "           [135, 139, 153,  ..., 185, 189, 186],\n",
       "           [137, 144, 151,  ..., 183, 183, 181]],\n",
       " \n",
       "          [[218, 218, 218,  ..., 200, 200, 200],\n",
       "           [218, 218, 218,  ..., 200, 200, 200],\n",
       "           [220, 220, 220,  ..., 200, 200, 200],\n",
       "           ...,\n",
       "           [ 68,  82, 101,  ..., 140, 136, 135],\n",
       "           [ 83,  85,  99,  ..., 135, 139, 136],\n",
       "           [ 85,  91,  98,  ..., 133, 133, 131]],\n",
       " \n",
       "          [[205, 205, 205,  ..., 181, 181, 181],\n",
       "           [207, 207, 207,  ..., 181, 181, 181],\n",
       "           [211, 211, 211,  ..., 181, 181, 181],\n",
       "           ...,\n",
       "           [ 35,  43,  56,  ...,  87,  83,  82],\n",
       "           [ 43,  42,  52,  ...,  82,  86,  83],\n",
       "           [ 41,  43,  49,  ...,  80,  80,  78]]],\n",
       " \n",
       " \n",
       "         [[[ 54,  53,  55,  ...,  48,  48,  51],\n",
       "           [ 55,  55,  55,  ...,  48,  48,  49],\n",
       "           [ 59,  59,  57,  ...,  49,  48,  47],\n",
       "           ...,\n",
       "           [168, 167, 173,  ...,  14,  13,  12],\n",
       "           [171, 170, 169,  ...,  16,  13,  11],\n",
       "           [165, 169, 171,  ...,  15,  11,  10]],\n",
       " \n",
       "          [[124, 123, 122,  ..., 116, 116, 115],\n",
       "           [124, 123, 122,  ..., 115, 115, 115],\n",
       "           [125, 124, 123,  ..., 114, 114, 116],\n",
       "           ...,\n",
       "           [151, 150, 156,  ...,  19,  15,  14],\n",
       "           [154, 153, 153,  ...,  19,  15,  13],\n",
       "           [148, 152, 155,  ...,  16,  13,  12]],\n",
       " \n",
       "          [[193, 195, 199,  ..., 191, 188, 186],\n",
       "           [193, 195, 198,  ..., 192, 190, 187],\n",
       "           [195, 197, 200,  ..., 193, 191, 189],\n",
       "           ...,\n",
       "           [131, 130, 136,  ...,  16,  10,   9],\n",
       "           [134, 133, 132,  ...,  12,  10,   8],\n",
       "           [128, 132, 132,  ...,  13,   8,   7]]],\n",
       " \n",
       " \n",
       "         [[[216, 217, 219,  ..., 209, 218, 223],\n",
       "           [226, 222, 217,  ..., 215, 223, 225],\n",
       "           [229, 229, 224,  ..., 221, 221, 219],\n",
       "           ...,\n",
       "           [225, 223, 209,  ..., 130, 126, 128],\n",
       "           [214, 217, 227,  ..., 126, 133, 134],\n",
       "           [215, 211, 208,  ..., 120, 122, 133]],\n",
       " \n",
       "          [[229, 230, 230,  ..., 222, 226, 232],\n",
       "           [239, 235, 228,  ..., 227, 232, 235],\n",
       "           [240, 240, 234,  ..., 233, 230, 227],\n",
       "           ...,\n",
       "           [208, 211, 193,  ...,  71,  67,  69],\n",
       "           [188, 196, 207,  ...,  67,  74,  75],\n",
       "           [180, 172, 171,  ...,  61,  63,  74]],\n",
       " \n",
       "          [[245, 246, 245,  ..., 240, 244, 246],\n",
       "           [249, 245, 242,  ..., 244, 250, 250],\n",
       "           [249, 249, 246,  ..., 247, 246, 245],\n",
       "           ...,\n",
       "           [199, 200, 183,  ...,  29,  25,  27],\n",
       "           [184, 191, 200,  ...,  25,  32,  33],\n",
       "           [170, 163, 160,  ...,  19,  21,  32]]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature1, feature2, _ = next(iter(train_dataloader))\n",
    "feature1, feature2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58ff61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruiqinng\\miniconda3\\envs\\dai\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0799],\n",
      "        [-0.0835],\n",
      "        [-0.0808],\n",
      "        [-0.0787],\n",
      "        [-0.0797],\n",
      "        [-0.0795],\n",
      "        [-0.0850],\n",
      "        [-0.0853],\n",
      "        [-0.0802],\n",
      "        [-0.0801],\n",
      "        [-0.0811],\n",
      "        [-0.0830],\n",
      "        [-0.0877],\n",
      "        [-0.0794],\n",
      "        [-0.0814],\n",
      "        [-0.0812],\n",
      "        [-0.0800],\n",
      "        [-0.0827],\n",
      "        [-0.0819],\n",
      "        [-0.0839],\n",
      "        [-0.0856],\n",
      "        [-0.0875],\n",
      "        [-0.0790],\n",
      "        [-0.0819],\n",
      "        [-0.0807],\n",
      "        [-0.0756],\n",
      "        [-0.0847],\n",
      "        [-0.0822],\n",
      "        [-0.0845],\n",
      "        [-0.0842],\n",
      "        [-0.0822],\n",
      "        [-0.0803],\n",
      "        [-0.0851],\n",
      "        [-0.0775],\n",
      "        [-0.0840],\n",
      "        [-0.0815],\n",
      "        [-0.0800],\n",
      "        [-0.0838],\n",
      "        [-0.0816],\n",
      "        [-0.0764],\n",
      "        [-0.0832],\n",
      "        [-0.0854],\n",
      "        [-0.0812],\n",
      "        [-0.0790],\n",
      "        [-0.0786],\n",
      "        [-0.0852],\n",
      "        [-0.0839],\n",
      "        [-0.0818],\n",
      "        [-0.0802],\n",
      "        [-0.0864],\n",
      "        [-0.0790],\n",
      "        [-0.0803],\n",
      "        [-0.0822],\n",
      "        [-0.0819],\n",
      "        [-0.0850],\n",
      "        [-0.0816],\n",
      "        [-0.0753],\n",
      "        [-0.0815],\n",
      "        [-0.0842],\n",
      "        [-0.0838],\n",
      "        [-0.0872],\n",
      "        [-0.0841],\n",
      "        [-0.0830],\n",
      "        [-0.0838]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "feature1 = feature1.to(device)\n",
    "feature2 = feature2.to(device)\n",
    "\n",
    "output = model(feature1, feature2)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22f97ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7020f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
